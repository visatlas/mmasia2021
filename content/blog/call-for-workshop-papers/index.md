---
title: Call for Workshop Papers
datePublished: "2021-08-18"
dateModified: "2021-08-18"
description: ACM Multimedia Asia 2021 Calling for Workshop Papers.
---

Three workshop proposals were accepted for the ACM Multimedia Asia 2021 edition.

## Workshop 1: Visual Tasks and Challenges under Low-quality Multimedia Data

[*https://workshopcv.github.io/*](https://workshopcv.github.io/)

### Overview

The field of computer vision has been a research hotspot, and early research focused on high-quality image or daytime scenes with better illumination. Existing vision techniques have achieved better results with an approximately accuracy rate of 96% with these conditions. In practice, nearly 90% of criminal activities occur in the night scenes with low quality, especially in major cases. The video data collected by the surveillance system in these scene has low contrast and poor quality. According to the Ministry of Public Security Evidence Identification Center (China), the proportion of poor quality video images at night is as high as 95%, and the performance of current methods on low- quality visible images is low, which is difficult to cope with the actual security needs. There is an urgent need to optimize this problem. 

### Challenge

The goal of this challenges to:

- Bring together the state of the art research on object detection under low illumination;
- Call for a coordinated effort to understand the opportunities and challenges emerging in object detection;
- Identify key tasks and evaluate the state-of-the-art methods;
- Showcase innovative methodologies and ideas;
- Introduce interesting real-world intelligent object detection under low illumination;
- Propose new real-world datasets and discuss future directions. We believe the workshop will offer a timely collection of research updates to benefit the researchers and practitioners working in the broad computer vision, multimedia, and pattern recognition communities.


### Call for Papers

Except for the challenge, we solicit original research and survey papers in (but not limited to) the following topics:
1) Pedestrian detection in low illumination, low resolution, rain and fog, etc.
2) Object detection in low illumination, low resolution, rain and fog, etc.
3) Person re-identification in low illumination, low resolution, rain and fog, etc.
4) Object recognition in low illumination, low resolution, rain and fog, etc.
5) Segmentation in low illumination, low resolution, rain and fog, etc.
6) Counting in low illumination, low resolution, rain and fog, etc.

### Important Dates

-	Release of Training Date: Aug 10, 2021, 23:59 AoE
-	Release of Validation Date:	Sep 10, 2021, 23:59 AoE
-	Release of Test Date: Sep 24, 2021, 23:59 AoE
-	Result Submission Close: Oct 8, 2021, 23:59 AoE
-	Workshop Paper Submission: Oct 18, 2021, 23:59 AoE
-	Workshop Notification: Nov 1, 2021, 23:59 AoE

### Organisers
- **Jing Xiao**, ([jing@whu.edu.cn](mailto:jing@whu.edu.cn)), Wuhan University, China 
- **Xiao Wang**, ([hebeiwangxiao@whu.edu.cn](mailto:hebeiwangxiao@whu.edu.cn)), Wuhan University, China 
- **Liang Liao**, ([liang@nii.ac.jp](mailto:liang@nii.ac.jp)), National Institute of Informaties, Japan 
- **Shin'ichi Satoh**, ([satoh@nii.ac.jp](mailto:satoh@nii.ac.jp)), National Institute of Informaties, Japan 
- **Chia-wen Lin**, ([cwlin@ee.nthu.edu.tw](mailto:cwlin@ee.nthu.edu.tw)), National Tsing Hua University, Taiwan 






&nbsp;
***

## Workshop 2: Multi-Modal Embedding and Understanding 

### Overview
We human perceive the physical world via multiple ways, e.g., watching, touching, hearing, and so on, which means that we process multi-modal information for environment perception. Multi-modal understanding plays a crucial role in enabling the machine with such ability. Due to its research significance, multi-modal embedding and understanding has gained much research attention and achieved many progresses in the past couples of years. The recent advances in deep learning inspire us to explore more and deeper for the multi-modal embedding and understanding, such as the self-supervised learning and pre-training in it. In this workshop, we aim to bring together researchers from the field of multimedia to discuss recent research and future directions for multi-modal embedding and understanding, and their applications.

### Call for Papers

Multi-modal understanding are important and fundamental problems in the field of multimodal analysis, which have been attracting much research attention in recent years. Previous works have explored shallow embedding and understanding in many downstream tasks, including cross-modal retrieval, visual navigation, VQA, visual captioning, etc. To encourage researchers to explore new and advanced techniques in this area, we are organizing a workshop on “multi-modal embedding and understanding” with the conjunction of ACM MM Asia 2021, and calling for contributions. The included (but not limited) topics are as follows:
1)	 Large-scale pre-training for multi-modal embedding and understanding
2)	 Self-supervised learning in multi-modal embedding and understanding
3)	 Semi-supervised learning in multi-modal embedding and understanding
4)	 Contrastive learning in multi-modal embedding and understanding
5)	 Interpretability in multi-modal embedding and understanding
6) 	 Interactive multi-modal understanding
7)	 Trust AI for multi-modal understanding
8)	 Cross-modal matching and retrieval
9)	 Cross-modal understanding
10)  Multi-modal deep fake generation and detection
11)	 And other related……

### Submission Guidelines
**Format:** Submitted papers (.pdf format) must use the ACM Article Template [*https://www.acm.org/publications/proceedings-template*](https://www.acm.org/publications/proceedings-template). Please remember to add Concepts and Keywords.

**Length:** Papers must be **no longer than 6 pages**, including all text and figures, and up to two additional pages may be added for references. The reference pages must only contain references. Over-length papers will be rejected without review.

### Important dates
- Paper submission deadline: Oct 13, 2021, 23:59 AoE 
- Notifications of acceptance: Nov 3, 2021
- Camera-ready submission: Nov 10, 2021, 23:59 AoE

### Organisers
- **Wenguan Wang**, ETH Zurich, Switzerland
- **Xiaojun Chang**, RMIT, Australia
- **Yanli Ji**, University of Electronic Science and Technology of China, China
- **Yi Bin**, University of Electronic Science and Technology of China, China





